## ----load packages----------------------------------------------------------
library(tidyverse)
library(ggthemes)
library(maps)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(viridis)
library(nullabor)
library(splitstackshape)
library(plotly)
library(forecast)
library(readxl)
# remotes::install_github("wmurphyrd/fiftystater")
library(fiftystater)


## ----lineup 1, fig.height=8, fig.width=8---------------------------------
# Make a lineup of the mtcars data, 20 plots, one is the data,
# and the others are null plots. Which one is different?
set.seed(20190709)
ggplot(lineup(null_permute('mpg'), mtcars), aes(mpg, wt)) +
  geom_point() +
  facet_wrap(~ .sample)


## ----lineup 2, fig.height=6----------------------------------------------
# Assessing model fit, using a lineup of residual plots, 19 are nulls, and one is the
# residual plot. Is there structure in the residual plot that identifies it as having
# less than random variation. Nulls are generated by `rotating` residuals after model fit.
tips <- read_csv("http://www.ggobi.org/book/data/tips.csv")
x <- lm(tip ~ totbill, data = tips)
tips.reg <- data.frame(tips, .resid = residuals(x), .fitted = fitted(x))
ggplot(lineup(null_lm(tip ~ totbill, method = 'rotate'), tips.reg)) +
  geom_point(aes(x = totbill, y = .resid)) +
  facet_wrap(~ .sample)


## ----lineup 3, fig.height=6----------------------------------------------
# Assessing time series model fit using simulation to produce null plots.
data(aud)
l <- lineup(null_ts("rate", auto.arima), aud)
ggplot(l, aes(x=date, y=rate)) + geom_line() +
  facet_wrap(~.sample, scales="free_y") +
  theme(axis.text = element_blank()) +
  xlab("") + ylab("")


## ----lets talk TB, echo=FALSE--------------------------------------------
tb <- read_csv(here::here("data/TB_notifications_2019-07-01.csv")) %>%
  select(country, iso3, year, new_sp_m04:new_sp_fu) %>%
  gather(stuff, count, new_sp_m04:new_sp_fu) %>%
  separate(stuff, c("stuff1", "stuff2", "sexage")) %>%
  select(-stuff1, -stuff2) %>%
  mutate(sex=substr(sexage, 1, 1),
         age=substr(sexage, 2, length(sexage))) %>%
  select(-sexage)

# Filter years between 1997 and 2012 due to missings
tb_us <- tb %>%
  filter(country == "United States of America") %>%
  filter(!(age %in% c("04", "014", "514", "u"))) %>%
  filter(year > 1996, year < 2013)


## ----fig.width=10, fig.height=3------------------------------------------
ggplot(tb_us, aes(x = year, y = count, fill = sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(~ age) +
  scale_fill_brewer(palette="Dark2")


## ----generate a lineup of three binomial simulations, echo=TRUE----------
# Make expanded rows of categorical variables
# matching the counts of aggregated data.
# sex needs to be converted to 0, 1 to
# match binomial simulations
tb_us_long <- expandRows(tb_us, "count")
tb_us_long <- tb_us_long %>%
  mutate(sex01 = ifelse(sex=="m", 0, 1)) %>%
  select(-sex)

# Generate a lineup of three, randomly choose one of the
# positions to place true data.
# Compute counts again.
pos = sample(1:3, 1)
l <- lineup(null_dist(var="sex01", dist="binom",
                      list(size=1, p=0.5)),
            true=tb_us_long, n=3, pos=pos)
l <- l %>%
  group_by(.sample, year, age) %>%
  dplyr::count(sex01)


## ----plot the lineup, fig.height=8, fig.width=10-------------------------
ggplot(l, aes(x = year, y = n, fill = factor(sex01))) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(.sample ~ age) +
  scale_fill_brewer(palette="Dark2") +
  theme(legend.position="none")


## ----a more complicated null, echo=TRUE----------------------------------
# Compute proportion across all data
tbl <- tb_us %>% group_by(sex) %>% summarise(count=sum(count))
tbl
p <- tbl$count[1]/sum(tbl$count)

pos = sample(1:3, 1)
l <- lineup(null_dist(var="sex01", dist="binom",
                      list(size=1, p=p)),
            true=tb_us_long, n=3, pos=pos)
l <- l %>%
  group_by(.sample, year, age) %>%
  dplyr::count(sex01)



## ----fig.height=8, fig.width=10------------------------------------------
ggplot(l, aes(x = year, y = n, fill = factor(sex01))) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(.sample ~ age) +
  scale_fill_brewer(palette="Dark2") +
  theme(legend.position="none")

## ----compute pvalue------------------------------------------------------
pvisual(4, 17, m=20)


## ----emake a choropleth map, cho=TRUE------------------------------------
world_map <- map_data("world")
usa <- map_data("usa")
tb_names <- tb %>%
  mutate(region=recode(country,
                       "United States of America"="USA",
                       "United Kingdom"="UK",
                       "Russian Federation"="Russia"))


## ----compute the linear trend in counts, echo=TRUE-----------------------
# This is sophisticated code to compute the linear trend in counts
# for each country.
tb_names_inc <- tb_names %>%
  group_by(region) %>%
  nest() %>%
  mutate(
    model = purrr::map(data, ~ lm(count ~ year, data = .))
) %>%
  unnest(model %>% purrr::map(broom::tidy)) %>%
  select(region, term, estimate) %>%
  spread(term, estimate)


## ----one way to make the map is use geom_map, echo=TRUE------------------
ggplot(tb_names_inc, aes(map_id = region)) +
    geom_map(aes(fill=year), map = world_map, color="grey70", size=0.3, na.rm=TRUE) +
    expand_limits(x = world_map$long, y = world_map$lat) +
    theme_few() +
    scale_fill_viridis("trend") +
    theme(legend.position = "bottom",
         axis.ticks = element_blank(),
         axis.title = element_blank(),
         axis.text =  element_blank()) +
    guides(fill = guide_colorbar(barwidth = 15, barheight = .5))


## ----aother approach is to join the polygon data, echo=TRUE--------------
tb_map <- left_join(world_map, tb_names_inc, by="region")
ggplot(tb_map) +
  geom_polygon(aes(x=long, y=lat, group=group, fill=year)) +
      theme_few() +
    scale_fill_viridis("trend", na.value = "grey70") +
    theme(legend.position = "bottom",
         axis.ticks = element_blank(),
         axis.title = element_blank(),
         axis.text =  element_blank()) +
    guides(fill = guide_colorbar(barwidth = 15, barheight = .5))


## ----make a map lineup, fig.height=6, fig.width=10-----------------------
# Read xlsx spreadsheet on cancer incidence in USA, for a more
# complex lneup example, a lineup of maps
incd <- read_xlsx(here::here("data/IncRate.xlsx"), skip=6, sheet=2) %>%
  filter(!(State %in% c("All U.S. combined", "Kansas"))) %>%
  select(State, `Melanoma of the skin / Both sexes combined`) %>%
  rename(Incidence=`Melanoma of the skin / Both sexes combined`) %>%
  mutate(Incidence = as.numeric(substr(Incidence, 1, 3)))

# State names need to coincide between data sets
incd <- incd %>% mutate(State = tolower(State))

# Choose a position
pos <- 6

# Make lineup of cancenr incidence
incd_lineup <- lineup(null_permute('Incidence'), incd, n=12, pos=pos)

# Join cancer incidence data to map polygons
incd_map <- left_join(fifty_states, filter(incd_lineup, .sample==1),
                      by=c("id"="State"))
for (i in 2:12) {
  x <- left_join(fifty_states, filter(incd_lineup, .sample==i),
                      by=c("id"="State"))
  incd_map <- bind_rows(incd_map, x)
}
# Remove Kansas - it was missing the cancer data
incd_map <- incd_map %>% filter(!is.na(.sample))

# Plot the maps as a lineup
ggplot(incd_map) +
  geom_polygon(aes(x=long, y=lat, fill = Incidence, group=group)) +
  expand_limits(x = incd_map$long, y = incd_map$lat) +
  #coord_map() +
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "") +
  scale_fill_distiller(palette="YlGn", type="seq", direction=1) +
  theme(legend.position = "none",
        panel.background = element_blank()) +
  facet_wrap(~.sample, ncol=4)

