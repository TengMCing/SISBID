---
title: "Advanced plots and inference"
subtitle: "SISBID 2018 <br> https://github.com/dicook/SISBID"
author: "Di Cook (dicook@monash.edu, @visnut) <br> Heike Hofmann (heike.hofmann@gmail.com, @heike_hh)"
date: "07/25-27/2018"
output:
  xaringan::moon_reader:
    css: ["default", "myremark.css"]
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      incremental: true
---

```{r echo = FALSE, warning = FALSE, message=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  comment = "",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE,
  fig.retina = 4
)
```

```{r echo=FALSE}
library(tidyverse)
library(ggthemes)
library(maps)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(HLMdiag)
library(viridis)
library(nullabor)
library(splitstackshape)
library(forcats)
library(janitor)
```

# Tidy data and random variables

- The concept of tidy data matches elementary statistics
- Tabular form puts variables in columns and observations in rows
- Not all tabular data is in this form
- This is the point of tidy data

$$X = \left[ \begin{array}{rrrr}
           X_1 & X_2 & ... & X_p 
           \end{array} \right] \\
  = \left[ \begin{array}{rrrr}
           X_{11} & X_{12} & ... & X_{1p} \\
           X_{21} & X_{22} & ... & X_{2p} \\
           \vdots & \vdots & \ddots& \vdots \\
           X_{n1} & X_{n2} & ... & X_{np}
           \end{array} \right]$$

- $X_1 \sim N(0,1), ~~X_2 \sim exp(1) ...$

---
# Grammar of graphics and statistics

- A statistic is a function on the values of items in a sample, e.g. for $n$ iid random variates $\bar{X}_1=\sum_{i=1}^n X_{i1}$, $s_1^2=\frac{1}{n-1}\sum_{i=1}^n(X_{i1}-\bar{X}_1)^2$
- We study the behaviour of the statistic over all possible samples of size $n$. 
- The grammar of graphics is the mapping of (random) variables to graphical elements, making plots of data into statistics

```{r echo=FALSE}
tb <- read_csv("../data/TB_notifications_2018-03-18.csv") %>% 
  select(country, iso3, year, new_sp_m04:new_sp_fu) %>%
  gather(stuff, count, new_sp_m04:new_sp_fu) %>%
  separate(stuff, c("stuff1", "stuff2", "genderage")) %>%
  select(-stuff1, -stuff2) %>%
  mutate(gender=substr(genderage, 1, 1), 
         age=substr(genderage, 2, length(genderage))) %>%
  select(-genderage)

tb_us <- tb %>% 
  filter(country == "United States of America") %>%
  filter(!(age %in% c("04", "014", "514", "u"))) %>%
  filter(year > 1996, year < 2013) %>%
  select(year, count, gender, age)
```

---
# Inference

- Choice of plot implicitly sets $H_0$, $H_1$
- Generically, we are thinking  $H_0$: no pattern, $H_1$: pattern, but the choice of plot makes this much more explicit

---
# Let's talk TB

```{r fig.width=10, fig.height=3}
ggplot(tb_us, aes(x = year, y = count, fill = gender)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(~ age) +
  scale_fill_brewer(palette="Dark2")
```

There are many aspects of this plot, this is what we said earlier:

- *Across all ages, and years, the proportion of males having TB is higher than females*
- These proportions tend to be higher in the middle age groups, for all years.
- Relatively similar proportions across years.

---
# Null hypothesis

The plot is constructed by plotting count against year, separately by age group, and coloured by gender. 

- By colouring by gender, we make this a primary comparison
- Proportion of gender, conditional on age group and year is the query being addressed by this plot.

*Null hypothesis*: TB incidence is spread equally among men and women, regardless of age and year.
*Alternative hypothesis*: It isn't.

---

```{r echo=TRUE}
# Make expanded rows of categorical variables
# matching the counts of aggregated data.
# Gender needs to be converted to 0, 1 to 
# match binomial simulations
tb_us_long <- expandRows(tb_us, "count")
tb_us_long <- tb_us_long %>%
  mutate(gender01 = ifelse(gender=="m", 0, 1)) %>%
  select(-gender)

# Generate a lineup of three, randomly choose one of the
# positions to place true data.
# Compute counts again.
pos = sample(1:3, 1)
l <- lineup(null_dist(var="gender01", dist="binom", 
                      list(size=1, p=0.5)), 
            true=tb_us_long, n=3, pos=pos)
l <- l %>%
  group_by(.sample, year, age) %>%
  dplyr::count(gender01)
```

---

```{r fig.height=8, fig.width=10}
ggplot(l, aes(x = year, y = n, fill = factor(gender01))) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(.sample ~ age) +
  scale_fill_brewer(palette="Dark2") + 
  theme(legend.position="none")
```

---
# More interesting null

*Null hypothesis*: TB incidence is has the same proportion of men and women, regardless of age and year.
*Alternative hypothesis*: It isn't.

```{r echo=TRUE}
# Compute proportion across all data
tbl <- tb_us %>% group_by(gender) %>% summarise(count=sum(count))
tbl
p <- tbl$count[1]/sum(tbl$count)

pos = sample(1:3, 1)
pos = sample(1:3, 1)
l <- lineup(null_dist(var="gender01", dist="binom", 
                      list(size=1, p=p)), 
            true=tb_us_long, n=3, pos=pos)
l <- l %>%
  group_by(.sample, year, age) %>%
  dplyr::count(gender01)

```

---

```{r fig.height=8, fig.width=10}
ggplot(l, aes(x = year, y = n, fill = factor(gender01))) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(.sample ~ age) +
  scale_fill_brewer(palette="Dark2") + 
  theme(legend.position="none")
```

---
# Important details

- The null hypothesis is determined based on the plot type
- It is not based on the structure seen in a data set

---
# Lineup

Embed the data plot in a field of null plots

```{r eval=FALSE}
library(nullabor)
pos <- sample(1:20, 1)
df_null <- lineup(null_permute('v1'), df, pos=pos)
ggplot(df_null, aes(x=v2, y=v1, fill=v2)) + 
  geom_boxplot() +
  facet_wrap(~.sample, ncol=5) + coord_flip()
```

Ask: Which plot is the most different?

---
# Evaluation

- Computing $p$-values
- Power $=$ signal strength

---
# p-values

Suppose $x$ individuals selected the data plot from a lineup of $m$ plots, shown to $K$ independent observers, then simplistically we can think about the probability of this happening, if the data plot is from the same distribution as the null plots. This yields a binomial formula:

$$P(X\geq x) = \sum_{i=x}^{K} \binom{K}{i} \left(\frac{1}{m}\right)^i\left(\frac{m-1}{m}\right)^{K-i}$$


For $x=4, K=17, m=20$

```{r}
pvisual(4, 17, m=20)
```

---
# Simulation approach

- Scenario I: in each of K evaluations a different data set and a different set of (m-1) null plots is shown.
- Scenario II: in each of K evaluations the same data set but a different set of (m-1) null plots is shown.
- Scenario III: the same lineup, i.e. same data and same set of null plots, is shown to K different observers.

---
# Simulation

Crucial idea: assign a p-value to each plot (data and null); under null hypothesis, this p-value is from U[0,1] 

Scenario I:
- for the $k$th lineup evaluation do:
 - pick 20 $p$-values from $U[0,1]$
 - for data plot compute 'strength' of other plots: $q = (1-p_\text{data})/\sum_j(1-p_j)$
 - Use $q$ to determine whether data was picked in simulation: $x_k \tilde B_{1,q}$
 - repeat above three steps $K$ times, and find the number of data picks $X = \sum_k x_k$
- Repeat N times to get distribution of $X$

---
# Simulation


Scenario II (same data, different nulls):
- for the $k$th lineup evaluation pick 20 $p$-values from $U[0,1]$:
- for data plot compute 'strength' of other plots: $q = (1-p_\text{data})/\sum_j(1-p_j)$
- Use $q$ to determine whether data was picked in simulation: $x_k \tilde B_{1,q}$
- find the number of data picks $X = \sum_k x_k$
- Repeat N times to get distribution of $X$

---
# Simulation


Scenario III (same data, same nulls):
- for the $k$th lineup evaluation pick $p_\text{data} \sim U[0,1]$:
 - pick 19 $p$-values from $U[0,1]$
 - for data plot compute 'strength' of other plots: $q = (1-p_\text{data})/\sum_j(1-p_j)$
 - simulate number of data picks $X ~ B_{K, q}$
- Repeat N times to get distribution of $X$


---
# Null-generating mechanisms

- Permutation: randomizing the order of one of the variables breaks association, but keeps marginal distributions the same
- Simulation: from a given distribution, or model. Assumption is that the data comes from that model 

---
class: inverse middle 
# Your turn

For these plot descriptions, decide on:

- null hypothesis
- null generating mechanism

---
class: inverse middle 
# Your turn

```{r echo=FALSE}
ggplot(autism, 
       aes(x=age2+2, y=vsae, group=childid, colour=gender)) + 
  geom_point() +
  geom_line() + xlim(c(0, 15)) +
  xlab("Age (in years)") + ylab("Vineland Socialization Age Equivalent")
```

---
class: inverse middle 
# Your turn

```{r echo=FALSE}
fly <- read_csv("../data/flying-etiquette.csv")
fly <- fly %>% clean_names()
fly$how_often_do_you_travel_by_plane <- 
  factor(fly$how_often_do_you_travel_by_plane, levels=c(
    "Never","Once a year or less","Once a month or less",
    "A few times per month","A few times per week","Every day"))
fly_sub <- fly %>% filter(how_often_do_you_travel_by_plane %in% 
                            c("Once a year or less","Once a month or less")) %>%
  filter(!is.na(do_you_ever_recline_your_seat_when_you_fly)) %>%
  filter(!is.na(age)) %>% filter(!is.na(gender))
ggplot(fly_sub, 
       aes(x=in_general_is_itrude_to_bring_a_baby_on_a_plane)) + 
  geom_bar(mapping=aes(fill=gender), position="fill") + 
  scale_fill_brewer(palette="Dark2") +
  coord_flip() 
```

---
# More on making maps

Make a choropleth map of the TB data across the globe. We will do something a little fancy first, by computing a linear regression model for each country, to extract the trend in TB counts. This trend will be used to colour the maps, to find the countries which have TB problems. 

A polygon map of the world is extracted from the maps package. *The names of countries needs to be synchronised between the TB data and the map data.*

```{r echo=TRUE}
world_map <- map_data("world")
tb_names <- tb %>% 
  mutate(region=recode(country, 
                       "United States of America"="USA", 
                       "United Kingdom"="UK",
                       "Russian Federation"="Russia"))
```

---

```{r echo=TRUE}
# This is sophisticated code to compute the linear trend in counts
# for each country.
tb_names_inc <- tb_names %>% 
  group_by(region) %>%
  nest() %>%
  mutate(
    model = purrr::map(data, ~ lm(count ~ year, data = .))
) %>%
  unnest(model %>% purrr::map(broom::tidy)) %>%
  select(region, term, estimate) %>% 
  spread(term, estimate)
```

---

One way to make the map is use `geom_map`, and link this dynamically with the TB data in the plotting code.

```{r echo=TRUE}
ggplot(tb_names_inc, aes(map_id = region)) + 
    geom_map(aes(fill=year), map = world_map, color="grey70", size=0.3) + 
    expand_limits(x = world_map$long, y = world_map$lat) +
    theme_few() +
    scale_fill_viridis("trend") + 
    theme(legend.position = "bottom",
         axis.ticks = element_blank(), 
         axis.title = element_blank(), 
         axis.text =  element_blank()) +
    guides(fill = guide_colorbar(barwidth = 15, barheight = .5))
```


---

Another approach is to join the polygon data with the TB data.

```{r echo=TRUE}
tb_map <- left_join(world_map, tb_names_inc, by="region")
ggplot(tb_map) + 
  geom_polygon(aes(x=long, y=lat, group=group, fill=year)) +
      theme_few() +
    scale_fill_viridis("trend") + 
    theme(legend.position = "bottom",
         axis.ticks = element_blank(), 
         axis.title = element_blank(), 
         axis.text =  element_blank()) +
    guides(fill = guide_colorbar(barwidth = 15, barheight = .5))

```

---
class: inverse middle 
# Your turn

Why is India showing a drastically increasing TB incidence. 
Make the plot of TB incidence for India. 

---
# Resources

- Hofmann, H., Follett, L., Majumder, M. and Cook, D. (2012) Graphical Tests for Power Comparison of Competing Designs, http://doi.ieeecomputersociety.org/10.1109/TVCG.2012.230.
- Wickham, H., Cook, D., Hofmann, H. and Buja, A. (2010) Graphical Inference for Infovis,  http://doi.ieeecomputersociety.org/10.1109/TVCG.2010.161. 

---
# Share and share alike

This work is licensed under the Creative Commons Attribution-Noncommercial 3.0 United States License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc/3.0/us/ or send a letter to Creative Commons, 171 Second Street, Suite 300, San Francisco, California, 94105, USA.
