---
title: "Multivariate data plots"
subtitle: "SISBID 2019 <br> https://github.com/dicook/SISBID"
author: "Di Cook (dicook@monash.edu, @visnut) <br> Heike Hofmann (heike.hofmann@gmail.com, @heike_hh)"
date: "07/24-26/2019"
output:
  xaringan::moon_reader:
    css: ["default", "myremark.css"]
    self_contained: false
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r echo = FALSE}
knitr::opts_chunk$set(
  echo=TRUE, 
  message = FALSE,
  warning = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE
)
```

```{r echo=FALSE}
library(tidyverse)
library(lubridate)
library(GGally)
# remotes::install_github("ggobi/tourr")
library(tourr)
library(purrr)
library(broom)
library(plotly)
```

class: inverse middle 
# Your turn

- What is multivariate data?
- What makes multivariate analysis different from univariate analysis?

```{r, eval=FALSE, echo = FALSE}
data is multivariate, if we have more information than a single aspect for each entity/person/experimental unit.
mutivariate analysis takes relationships between these different aspects into account.
```

---
# Main types of plots

- __pairwise plots__: explore association between pairs of variables
- __parallel coordinate plots__: use parallel axes to lay out many variables on a page
- __heatmaps__: represent data value using colour, present as a coloured table
- __tours__: sequence of projections of high-dimensional data, good for examining shape and distribution between many variables

---
# Scatterplot matrix: GGally

.pull-left[The basic plot plot for multivariate data is a scatterplot matrix. There are two functions available in the GGally package: `ggscatmat`, `ggpairs`.

<br>
<br>

*What do we learn?*

- clustering
- linear dependence
- marginal discrete distribution
]
.pull-right[
```{r scatterplot matrix, echo=TRUE, fig.width=6, fig.height=6}
# Make a simple scatterplot matrix of a classic data set
data(flea)
ggscatmat(flea, columns = 1:6)
```
]

---

.pull-left[
**Add some colour for groups**

<br>
<br>
<br>
<br>
<br>
<br>
*What do we learn?*

- clustering is due to the class variable
]
.pull-right[
```{r scatterplot matrix with colour, echo=TRUE, fig.width=8, fig.height=8}
# Re-make mapping colour to species (class)
data(flea)
ggscatmat(flea, columns = 1:6, color = "species") +
  theme(legend.position="bottom")
```
]


---
# Generalized pairs plot

.pull-left[
These functions strictly take numeric variables. For a wider variety of variable types, use `ggpairs`.

Its a bit slower, but it has a huge amount of flexibility.

```{r PISA data wrangling}
# Matrix plot when variables are not numeric
data(australia_PISA2012)
australia_PISA2012 <- australia_PISA2012 %>%
  mutate(desk = factor(desk), 
         room = factor(room),
         study = factor(study), 
         computer = factor(computer),
         software = factor(software), 
         internet = factor(internet),
         literature = factor(literature), 
         poetry= factor(poetry),
         art = factor(art), 
         textbook = factor(textbook),
         dictionary = factor(dictionary),
         dishwasher = factor(dishwasher))
```
]
.pull-right[
```{r generalised pairs plot, echo=TRUE, fig.width=6, fig.height=6}
australia_PISA2012 %>% 
  filter(!is.na(dishwasher)) %>% 
  ggpairs(columns=c(3, 15, 16, 21, 26))
```
]

---

```{r generalised pairs plot enhance plots, echo=TRUE, fig.width=6, fig.height=6}
# Modify the defaults, set the transparency of points since there is a lot of data
australia_PISA2012 %>% 
  filter(!is.na(dishwasher)) %>% 
  ggpairs(columns=c(3, 15, 16, 21, 26), 
          lower = list(continuous = wrap("points", alpha=0.05)))
```

---

.pull-left[
```{r design own plot function}
# Make a special style of plot to put in the matirx
my_fn <- function(data, mapping, method="loess", ...){
      p <- ggplot(data = data, mapping = mapping) + 
      geom_point(alpha=0.2, size=1) + 
      geom_smooth(method="lm", ...)
      p
}
```
<br>
<br>
<br>

*What do we learn?*

- moderate increase in all scores as more time is spent on homework
- test scores all have a very regular bivariate normal shape - is this simulated data? yes.
- having a dishwasher in the household corresponds to small increase in homework time
- very little but slight increase in scores with a dishwasher in household

]
.pull-right[
```{r generalised pairs plot enhance more, echo=TRUE, fig.width=6, fig.height=6}
australia_PISA2012 %>% 
  filter(!is.na(dishwasher)) %>% 
  ggpairs(columns=c(3, 15, 16, 21, 26), 
          lower = list(continuous = my_fn))

```
]

---
class: inverse middle

# Your turn

Re-make the plot with 

- side-by-side boxplots on the lower triangle, for the combo variables, 
- and the density plots in the upper triangle.

---
# Regression setting

.pull-left[
An alternative pairs plot that better matches this sort of data, where there is a response variable and explanatory variables. For this data, plot house price against all other variables.

```{r wrangle housing data}
housing <- read_csv(here::here("data/housing.csv")) %>%
  mutate(date = dmy(date)) %>%
  mutate(year = year(date)) %>%
  filter(year == 2016) %>%
  filter(!is.na(bedroom2), !is.na(price)) %>%
  filter(bedroom2 < 7, bathroom < 5) %>%
  mutate(bedroom2 = factor(bedroom2), 
         bathroom = factor(bathroom)) 
```
]
.pull-right[
```{r make a regression style pairs plot, out.width="100%", fig.width=8, fig.height=3}
ggduo(housing[, c(4,3,8,10,11)], 
      columnsX = 2:5, columnsY = 1, 
      aes(colour=type, fill=type), 
      types = list(continuous = 
                     wrap("smooth", 
                       alpha = 0.10)))
```
]

---
# Let's explore tuberculosis mortality

.pull-left[
This data set is available from WHO along with the incidence data. The package `getTBinR` is a good way to download the burden table, which contains (estimated) mortality rates. 

```{r how to pull the tb data directly, eval=FALSE}
# library(getTBinR)
# tb_burden <- get_tb_burden(verbose = FALSE)
# dict <- get_data_dict(verbose = FALSE)
# save(tb_burden, file="data/tb_burden.rda")
```

You have the data downloaded in the data directory already. We'd like to explore the rates across countries. To do this we will fit a linear model for each country and collect some statistics from each model fit. Using these, we'll extract countries with specific characteristics.
]
.pull-right[
```{r compute statistics on tb mortality trends}
# A more complex example of using the scatterplot matrix to explore
# a large collection of time series. Compute statistics for each time
# series, which might be called tignostics, and plot these. Explore 
# the scatterplot matrix for anomalies and clusters. 
load(here::here("data/tb_burden.rda"))
# Fit a model for each country, and extract statistics
tb_reg1 <- tb_burden %>%
  group_by(country) %>%
  nest() %>%
  mutate(model = purrr::map(data, ~lm(e_mort_exc_tbhiv_100k ~ year, data = .x) %>% 
                       tidy)) %>% 
  unnest(model) %>%
  select(country, term, estimate) %>%
  spread(term, estimate) %>%
  rename(intercept = `(Intercept)`, slope=year)
tb_reg2 <- tb_burden %>%
  group_by(country) %>%
  nest() %>%
  mutate(model = purrr::map(data, ~lm(e_mort_exc_tbhiv_100k ~ year, data = .x) %>% 
                       glance)) %>% 
  unnest(model) %>%
  select(country, r.squared, sigma, BIC, deviance)
tb_reg <- left_join(tb_reg1, tb_reg2)
# Drop the 0 deviance, 0 sigma countries
tb_reg <- tb_reg %>% filter(sigma > 0, BIC > -400)
```
]

---

.pull-left[
```{r explore tb mortality trends, echo=TRUE, fig.width=6, fig.height=6}
ggscatmat(tb_reg, columns=3:7)
```
]
.pull-right[
`r set.seed(20190709); emo::ji("fantasy")` `r set.seed(20190712); emo::ji("fantasy")` `r set.seed(20190711); emo::ji("fantasy")` **TWO MINUTE CHALLENGE**

What do you learn about mortality rates across the difference countries from this?
]

---

.pull-left[
`r icon::fa("hand-point-right")` **Add interactivity**

```{r wranglw data to show labels interactively, echo=TRUE}
# Add interaction to find the id's for countries that are anomalies
tb_reg_m <- as.data.frame(tb_reg[,3:7])
rownames(tb_reg_m) <- tb_reg$country
```

<br>
<br>

The row number of the data matrix that shows on mouseover can be used to find the country.


]
.pull-right[
```{r explore tb mortality trends interactively, echo=TRUE, fig.width=8, fig.height=7}
tb_reg_m %>% ggpairs() %>% ggplotly()
```
]

---
# Decreasing mortality


```{r plot the countries that have decreasing mortality trend, echo=TRUE, fig.width=7, fig.height=4}
# Use a dotplot with model overlaid, to better match analysis conducted
declining <- tb_reg %>% filter(slope < -3.5)
tb_burden %>% filter(country %in% declining$country) %>%
  ggplot(aes(x=year, y=e_mort_exc_tbhiv_100k)) + 
    geom_point() +
    geom_smooth(method="lm", se=F) +
  facet_wrap(~country, scales = "free_y")
```

---
# Increasing mortality

```{r explore tb mortality trends problem countries, echo=TRUE,  fig.width=7, fig.height=3}
increasing <- tb_reg %>% filter(slope > 1, r.squared > 0.5)
tb_burden %>% filter(country %in% increasing$country) %>%
  ggplot(aes(x=year, y=e_mort_exc_tbhiv_100k)) + 
    geom_point() +
    geom_smooth(method="lm", se=F) +
  facet_wrap(~country, scales = "free_y")
```

---
class: inverse middle

# Your turn

- Plot the countries that have the highest variance
- Plot the countries with the smallest variance, and highest slope
- Plot all the coutries in one plot, as transparent lines. 


---
# Tours of high-dimensions


Most of what you find when you google "visualising high-dimensions" is awful, e.g. use colour and symbol after 3D to show 5D; PCA, MDS, tSNE, are visualisation methods; "you can't see beyond 3D".... Rubbish!

**What are dimensions?**

<img src="cubes.png" style="width: 90%; align: center" />

- When you add another variable, you implicitly add another orthogonal axis. 
- The space is effectively a $p$-dimensional cube
- The data might not fill the cube, and then dimension reduction might make it a $k(<p)$-dimensional cube

---
# Quick intro

<img src="images/tourr.png" width="10%" />

*Without thinking too much*: How many clusters do you see?

```{r code for generating a 6D tour, eval=FALSE, echo=TRUE}
# The tour requires making many plots, and updating.
# The RStudio graphics device doesn't work well
# Open a graphics window
# quartz()  # Mac OSX
# X11()     # Windows
animate_xy(flea[,1:6], axes = "off")
```


---
# What is a tour?

.pull-left[
A grand tour is by definition a movie of low-dimensional projections constructed in such a way that it comes arbitrarily close to showing all possible low-dimensional projections; in other words, a grand tour is a space-filling curve in the manifold of low-dimensional projections of high-dimensional data spaces.

<img src="images/hands.png" width="60%">
]
.pull-right[
Movement patterns indicate structure:

<img src="images/tour_schematic.png" width="80%">
]
---

Here is a grand tour of a 3D classic data set

<iframe src="images/flea3d.html" width="800" height="500" scrolling="yes" seamless="seamless" frameBorder="0"> </iframe>

The axes show the combination of variables making up any particular 2D projection.

---

This is a grand tour of the full 6D. Can you see clusters? Corresponding to the colours? 

<iframe src="images/flea6d.html" width="800" height="500" scrolling="yes" seamless="seamless" frameBorder="0"> </iframe>

These two animations were made with `plotly`.

---
# Why use a tour?

Other than basic exploration:

- **initial data analysis**: to examine whether the data 
    - satisfies assumptions required for the method
    - has unexpected complications like outliers or nonlinearity
- **examine the model fit**:    
    - dimension reduction, e.g. to look at more than 2 PCs
    - clustering, and examine the model like the dendrogram in high-d, or the k-means, or the estimated model from model-based
    - classification: boundaries between classes, misclassifications, diagnostics like vote matrix from random forest

---
# Guided tour

The guided tour chooses new target projections by optimising a function of interest:

$$\mathop{\text{maximize}}_{\phi_{11},\dots,\phi_{p1}} f\left(\sum_{j=1}^p \phi_{j1}x_{ij}\right) \text{ subject to }
\sum_{j=1}^p \phi^2_{j1} = 1$$

- `holes`: This is an inverse Gaussian filter, which is optimised wheren there is not much data in the center of the projection, i.e. a "hole" or donut shape in 2D.
- `central mass`: The opposite of holes, high density in the centre of the projection, and often "outliers" on the edges. 
- `LDA`: An index based on the linear discrimination dimension reduction, optimised by projections where the named classes are most separated.

```{r guided tour 6D, eval=FALSE, echo=TRUE}
# The tour requires making many plots, and updating.
# The RStudio graphics device doesn't work well
# Open a graphics window
# quartz()  # Mac OSX
# X11()     # Windows
animate_xy(flea[,1:6], guided_tour(lda_pp(flea$species)), axes="bottomleft")
```

---
# Manual tour

This is a good way to determine how important a structure in the projection is to a particular variable contribution. You can "rotate" a variable out, and observe if the pattern remains or disappears. 

```{r generate a sequence to rotate a variable out of a projection, eval=FALSE, echo=TRUE}
# When you find a low dimensional projection from some other technique
# such as principal component analysis, linear discriminant analysis or 
# projection pursuit, it is useful to examine the sensitivity of structure
# to variables in the projection. This is the purpose of the manual tour. 
# Take a variable, and rotate it out of the projection and see if the structure
# persists or disappears.
flea_std <- tourr::rescale(flea[, 1:6])

rb <- basis_random(n = ncol(flea_std))
mtour <- manual_tour(basis = rb, manip_var = 4)
sshow <- array2df(array = mtour, data = flea_std)
render_plotly(slides = sshow)

render_plotly(slides = sshow, col = col_of(flea$species), 
  fps = 2)
```

---
# Examining models: randomForest

We will take a look at the vote matrix from a random forest fit, on the classic olive oil data. The vote matrix contains the proportion of times each observation is predicted to be in each class. Geometrically it is a simplex. Points close to a vertex, correspond to observations where the classifier almost always predicts to one class, that is, very certain. Points between vertices are observations with uncertainty.

```{r read and tour on in a classic data set, echo=TRUE, eval=FALSE}
olive <- read_csv("http://www.ggobi.org/book/data/olive.csv") %>%
  rename(name=X1)
olive <- olive %>%
  filter(region == 1) %>%
  mutate(area = factor(area))
pal <- brewer.pal(4, "Dark2")
col <- pal[olive$area]
# drop eicosenoic, all low for south
animate_xy(olive[,4:10], axes="bottomleft", col=col) 
# Drop Sicily
animate_xy(olive[olive$area!=4,4:10], axes="bottomleft", col=col[olive$area!=4]) 
```

---

```{r Fit a randomForest model an examine the vote matrix, echo=TRUE, eval=FALSE}
olive_rf <- randomForest(area~., data=olive[,-c(1, 2, 11)], importance=TRUE, proximity=TRUE)
olive_rf
vt <- data.frame(olive_rf$votes)
vt$area <- olive$area
ggscatmat(vt, columns=1:4, col="area") + 
  scale_colour_brewer("", palette="Dark2")
proj <- t(geozoo::f_helmert(4)[-1,])
vtp <- as.matrix(vt[,-5])%*%proj
vtp <- data.frame(vtp, area=vt$area)
ggscatmat(vtp, columns=1:3, col="area") + 
  scale_colour_brewer("", palette="Dark2")
pal <- brewer.pal(4, "Dark2")
col <- pal[as.numeric(vtp[, 4])]
animate_xy(vtp[,1:3], col=col, axes = "bottomleft")
# Add simplex
simp <- simplex(p=3)
sp <- data.frame(simp$points)
colnames(sp) <- c("x1", "x2", "x3")
colnames(vtp) <- c("x1", "x2", "x3")
vtp_s <- bind_rows(sp, vtp[,1:3])
animate_xy(vtp_s, col=col, axes = "bottomleft", edges=as.matrix(simp$edges), center=TRUE)
```

---
# Examining models: principal component analysis

.pull-left[
```{r tb pca analysis, eval=FALSE, echo=TRUE}
library(naniar) # Have missings!
tb_burden_wide <- tb_burden %>%
  select(country, g_whoregion, year, 
         e_mort_exc_tbhiv_100k) %>%
  spread(year, e_mort_exc_tbhiv_100k) %>%
  filter(complete.cases(.)) %>%
  rename(region = g_whoregion) %>%
  mutate(country = factor(country), 
         region = factor(region))
# vis_miss(tb_burden_wide)  
tb_pca <- prcomp(tb_burden_wide[,-c(1:2)], 
                 scale=FALSE, retx=TRUE)
screeplot(tb_pca, type="line")
tb_pcs <- bind_cols(as_tibble(tb_pca$x), 
                    tb_burden_wide[,1:2])
ggscatmat(tb_pcs, columns=1:3, color="region")
# quartz()
# X11()
pal <- brewer.pal(6, "Dark2")
col <- pal[as.numeric(as.factor(tb_pcs$region))]
animate_xy(tb_pcs[,1:4], col=col, 
           axes = "bottomleft")
```
]
.pull-right[
- The main structure is a "shuttlecock" shape: that most countries have similarly low rates and a handful of countries deviate from this. 
- A few, quite a few, outliers.
]

```{r tb mortality line plots, eval=FALSE, echo=FALSE}
tb_burden <- tb_burden %>%
  rename(region = g_whoregion)
ggplot(tb_burden, aes(x=year, y=e_mort_exc_tbhiv_100k, 
                      group=country, colour=region)) +
  geom_line() + facet_wrap(~region)
```


---
# Comparison to parallel coordinates

```{r tour again for comparison, eval=FALSE, echo=FALSE}
# quartz()
# X11()
pal <- brewer.pal(4, "Dark2")
col <- pal[olive$area]
# drop eicosenoic, all low for south
animate_xy(olive[,4:10], axes="bottomleft", col=col) 
# Drop Sicily
animate_xy(olive[olive$area!=4,4:10], axes="bottomleft", col=col[olive$area!=4]) 
```

Parallel coordinates show multiple dimensions by drawing lines connectiong observations plotted as univariate dotplots. It is a parallel geometric space rather than a Euclidean space. But is can be useful for getting a single static view, as an alternative to a scatterplot matrix.

```{r make a parallel coordinate plot of the olive data, eval=FALSE, echo=TRUE}
ggparcoord(olive, columns=4:10, groupColumn=3, order="anyClass") + 
  scale_colour_brewer("", palette="Dark2")
```

---
# Comparison to heatmap

A heatmap uses maps a quantitative variable to colour, and displays in a matrix layout. Often accompanied by a clustering, or ordering of rows and columns. Colour mapping of a quantitative variable is the lowest on the hierarchy of mappings, and difficult for a user to accurately read the information. The coordinate system underlying this form of mapping is not clear, its not Euclidean.

```{r make a heatmap of the olive data, eval=FALSE, echo=TRUE}
library(superheat)
superheat(olive[,4:10], scale=TRUE, 
          pretty.order.rows=TRUE, pretty.order.cols=TRUE,
          row.dendrogram = TRUE) 
```

---
# Making a tourr animation using plotly

The easiest approach is to use the `play_tour_path` function from `spinifex`. Either show it like, or save it to an html file for later replay with `save_html` from the `htmltools` package.

```{r plotly tourr, eval=FALSE, echo=TRUE}
flea_std <- rescale(tourr::flea[,1:6])
tpath    <- save_history(flea_std, max = 3)

pg <- play_tour_path(tour_path = tpath, data = flea_std, angle = .15)
pg 
save_html(pg, file="mytour.html")
```

---
# Making a tourr animation using gganimate

The function `render_gif` is available in the development version of the `tourr` package. It will save the tour projections as an animated gif.

```{r saving a tour as an animated fig using gganimate, eval=FALSE, echo=TRUE}
library(gganimate)
render_gif(flea[,1:6], grand_tour(), display_xy(axes="off"),
           frames=200, 
           gif_file="mytour.gif")
```


---
# Resources

- [GGobi web site](http://www.ggobi.org), [ggobi book](http://www.ggobi.org/book)
- Emerson et al (2013) The Generalized Pairs Plot, Journal of Computational and Graphical Statistics, 22:1, 79-91
- [Natalia da Silva](http://natydasilva.com/) [PPForest](https://cran.r-project.org/web/packages/PPforest/index.html) and [shiny app](https://natydasilva.shinyapps.io/shinyV03/).
- Eunkyung Lee [PPtreeViz](https://www.jstatsoft.org/article/view/v083i08)
- Wickham, Cook, Hofmann (2015) [Visualising Statistical Models: Removing the blindfold](http://dicook.org/publication/blindfold_2015/)
- Cook and Swayne (2007) [Interactive and Dynamic Graphics for Data Analysis](http://ggobi.org/book/)
- Wickham et al (2011) [tourr: An R Package for Exploring Multivariate Data with Projections](https://www.jstatsoft.org/article/view/v040i02/v40i02.pdf) and the R package [tourr](https://cran.r-project.org/web/packages/tourr/index.html)
- Schloerke et al (2016) [Escape from Boxland](https://journal.r-project.org/archive/2016/RJ-2016-044/index.html), [the web site zoo](http://schloerke.com/geozoo/) and the R package [geozoo](https://cran.r-project.org/web/packages/geozoo/index.html)

---
# Share and share alike

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
